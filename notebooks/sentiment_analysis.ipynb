{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis of Movie Reviews\n",
        "\n",
        "**Goal:** Build a model that reads a movie review (text) and predicts whether the sentiment is **positive** or **negative**.\n",
        "\n",
        "This is a classic **text classification** problem in NLP (Natural Language Processing). We will:\n",
        "1. Load and explore the data\n",
        "2. Preprocess the text so the model can use it\n",
        "3. Split data into train and test sets\n",
        "4. Train a classifier (TF-IDF + Logistic Regression)\n",
        "5. Evaluate accuracy and predict on new reviews\n",
        "\n",
        "Run each cell in order. If you get `ModuleNotFoundError: No module named 'nltk'`, run the cell below first to install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run this cell once if you get \"ModuleNotFoundError: No module named 'nltk'\"\n",
        "# Then restart the kernel (Kernel \u2192 Restart) and run the notebook from the top again.\n",
        "%pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Setup: Imports and project path\n",
        "\n",
        "We add the project root to Python\u2019s path so we can import from the `src` package (our own code). We then import:\n",
        "- **pandas** \u2013 for tables (DataFrames)\n",
        "- **train_test_split** (sklearn) \u2013 to split data into train and test\n",
        "- **config** \u2013 project settings (paths, test size, random seed)\n",
        "- **data_loader, text_preprocessing, model, evaluation** \u2013 our pipeline steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.abspath(\"..\"))\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from src.config import DATA_PATH, TEST_SIZE, RANDOM_STATE\n",
        "from src.data_loader import load_data\n",
        "from src.text_preprocessing import preprocess_text\n",
        "from src.model import build_model\n",
        "from src.evaluation import evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 1: Load the data\n",
        "\n",
        "We load the dataset from a CSV file. Each row has:\n",
        "- **review** \u2013 the raw text of the review\n",
        "- **sentiment** \u2013 the label: `positive` or `negative`\n",
        "\n",
        "`load_data` uses pandas to read the CSV. We use a path relative to the notebook (`../data/raw/...`) so it works when you run from the `notebooks/` folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load data (use path relative to project root when running from notebooks/)\n",
        "df = load_data(os.path.join(\"..\", \"data\", \"raw\", \"imdb_sample.csv\"))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1 (continued): Explore the data\n",
        "\n",
        "Before modeling, we always **explore the data**:\n",
        "- **Shape** \u2013 How many rows (reviews) and columns we have. We need enough data to train and test.\n",
        "- **Class distribution** \u2013 How many positive vs negative reviews. If one class dominates, the model might be biased; we might need balancing or different metrics (e.g. F1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[\"sentiment\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 2: Text preprocessing\n",
        "\n",
        "**Why preprocess?** Models don\u2019t read sentences; they need **numbers** or **fixed representations**. We also want to reduce noise and focus on meaningful words.\n",
        "\n",
        "Our `preprocess_text` function does three things:\n",
        "1. **Lowercasing** \u2013 \"Great\" and \"great\" become the same. Reduces vocabulary size and helps the model generalize.\n",
        "2. **Remove punctuation** \u2013 \"amazing!\" and \"amazing\" carry the same sentiment; punctuation often doesn\u2019t help for sentiment.\n",
        "3. **Remove stopwords** \u2013 Words like \"the\", \"is\", \"at\" appear in almost every sentence and usually don\u2019t indicate sentiment. Removing them shrinks the text and can improve signal.\n",
        "\n",
        "Below we compare one **raw** review with its **preprocessed** version so you can see the effect.  \n",
        "*(If the `nltk` package is installed, we use NLTK's full English stopword list; otherwise the code uses a small built-in list so the notebook still runs.)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: raw vs preprocessed\n",
        "sample = df[\"review\"].iloc[0]\n",
        "print(\"Raw:\", sample)\n",
        "print(\"Preprocessed:\", preprocess_text(sample))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 3: Train/test split\n",
        "\n",
        "**Why split?** We need to know if the model **generalizes** to new reviews it has never seen. If we evaluated on the same data we trained on, we'd only measure memorization, not real performance.\n",
        "\n",
        "We use `train_test_split` to put a fraction of the data (e.g. 25%) into **X_test, y_test** and the rest into **X_train, y_train**. The model is trained only on the train set; the test set is used once at the end to report accuracy and other metrics. We fix **random_state** so the split is reproducible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[\"review\"],\n",
        "    df[\"sentiment\"],\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 4: Build and train the model\n",
        "\n",
        "We use a **pipeline** with two steps:\n",
        "\n",
        "1. **TF-IDF vectorizer**  \n",
        "   - **TF** (Term Frequency): how often a word appears in a document.  \n",
        "   - **IDF** (Inverse Document Frequency): downweights words that appear in many documents (e.g. \"movie\") and upweights rarer, more discriminative words.  \n",
        "   - Together, TF-IDF turns each review into a **vector of numbers** (one number per word in the vocabulary). Our `preprocess_text` is passed as the **preprocessor** so every review is cleaned before counting.\n",
        "\n",
        "2. **Logistic Regression**  \n",
        "   - A linear classifier: it learns weights for each TF-IDF feature and combines them to predict positive vs negative.  \n",
        "   - Fast, interpretable, and often works very well on TF-IDF text features.\n",
        "\n",
        "**Training:** `model.fit(X_train, y_train)` makes the pipeline (1) preprocess and vectorize the training reviews, then (2) fit the logistic regression on those vectors and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = build_model(preprocess_text)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 5: Evaluate on the test set\n",
        "\n",
        "We measure performance on the **held-out test set** (data the model never saw during training):\n",
        "\n",
        "- **Accuracy** \u2013 Fraction of test reviews classified correctly. Simple and intuitive.\n",
        "- **Classification report** \u2013 For each class (positive/negative) we get:\n",
        "  - **Precision** \u2013 Of all reviews predicted as positive, how many were actually positive?\n",
        "  - **Recall** \u2013 Of all actually positive reviews, how many did we predict as positive?\n",
        "  - **F1-score** \u2013 Harmonic mean of precision and recall; useful when classes are imbalanced.\n",
        "\n",
        "This tells us whether the model is good enough and whether it favors one class over the other.  \n",
        "*Note: This notebook uses a very small sample dataset (few rows), so metrics may look uneven. With more data, you'd expect more stable and meaningful numbers.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "evaluate(model, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 6: Predict on new reviews\n",
        "\n",
        "Finally, we use the trained model to **predict sentiment for new text**. The pipeline automatically preprocesses and vectorizes the new reviews with the same steps used in training, then the classifier outputs a label (positive/negative) for each one. This is how you would use the model in an app or script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_reviews = [\n",
        "    \"The movie was boring and long\",\n",
        "    \"Amazing film, highly recommend!\",\n",
        "]\n",
        "model.predict(new_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}